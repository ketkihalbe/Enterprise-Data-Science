{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1eaa4a23",
   "metadata": {},
   "source": [
    "# Project: Development of COVID19 Dynamic Dashboard Prototype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0abdd30f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing Required Libraries\n",
    "\n",
    "import subprocess\n",
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from datetime import datetime\n",
    "\n",
    "import requests\n",
    "import json\n",
    "\n",
    "from sklearn import linear_model\n",
    "from scipy import signal\n",
    "\n",
    "import dash\n",
    "dash.__version__\n",
    "from dash import dcc\n",
    "from dash import html\n",
    "from dash.dependencies import Input, Output,State\n",
    "\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "reg = linear_model.LinearRegression(fit_intercept=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f096b5c7",
   "metadata": {},
   "source": [
    "# Data Preperation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e0e7e096",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data Gathering from Website\n",
    "\n",
    "def get_johns_hopkins():\n",
    "    git_pull = subprocess.Popen( \"/usr/bin/git pull\" ,\n",
    "                         cwd = os.path.dirname( '../data/raw/COVID-19/' ),\n",
    "                         shell = True,\n",
    "                         stdout = subprocess.PIPE,\n",
    "                         stderr = subprocess.PIPE )\n",
    "    (out, error) = git_pull.communicate()\n",
    "\n",
    "\n",
    "    print(\"Error : \" + str(error))\n",
    "    print(\"out : \" + str(out))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c4b69318",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Gathering Data for Germany\n",
    "\n",
    "def get_current_data_germany():\n",
    "    data=requests.get('https://services7.arcgis.com/mOBPykOjAyBO2ZKk/arcgis/rest/services/RKI_Landkreisdaten/FeatureServer/0/query?where=1%3D1&outFields=*&outSR=4326&f=json')\n",
    "\n",
    "    json_object=json.loads(data.content)\n",
    "    full_list=[]\n",
    "    for pos,each_dict in enumerate (json_object['features'][:]):\n",
    "        full_list.append(each_dict['attributes'])\n",
    "\n",
    "    pd_full_list=pd.DataFrame(full_list)\n",
    "    pd_full_list.to_csv('../data/raw/NPGEO/GER_state_data.csv',sep=';')\n",
    "    print(' Number of regions rows: '+str(pd_full_list.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "be7ec983",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error : b'The system cannot find the path specified.\\r\\n'\n",
      "out : b''\n",
      " Number of regions rows: 411\n"
     ]
    }
   ],
   "source": [
    "get_johns_hopkins()\n",
    "get_current_data_germany()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bf725264",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Transforming COVID data in Relational DataSet\n",
    "\n",
    "def store_relational_JH_data():\n",
    "    data_path='../data/raw/COVID-19/csse_covid_19_data/csse_covid_19_time_series/time_series_covid19_confirmed_global.csv'\n",
    "    pd_raw=pd.read_csv(data_path)\n",
    "\n",
    "    pd_data_base=pd_raw.rename(columns={'Country/Region':'country',\n",
    "                      'Province/State':'state'})\n",
    "\n",
    "    pd_data_base['state']=pd_data_base['state'].fillna('no')\n",
    "\n",
    "    pd_data_base=pd_data_base.drop(['Lat','Long'],axis=1)\n",
    "\n",
    "\n",
    "    pd_relational_model=pd_data_base.set_index(['state','country']) \\\n",
    "                                .T                              \\\n",
    "                                .stack(level=[0,1])             \\\n",
    "                                .reset_index()                  \\\n",
    "                                .rename(columns={'level_0':'date',\n",
    "                                                   0:'confirmed'},\n",
    "                                                  )\n",
    "\n",
    "    pd_relational_model['date']=pd_relational_model.date.astype('datetime64[ns]')\n",
    "\n",
    "    pd_relational_model.to_csv('../data/processed/COVID_relational_confirmed.csv',sep=';',index=False)\n",
    "    print(' Number of rows stored: '+str(pd_relational_model.shape[0]))\n",
    "    print(' Latest date is: '+str(max(pd_relational_model.date)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f853ecbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Number of rows stored: 260490\n",
      " Latest date is: 2022-07-23 00:00:00\n"
     ]
    }
   ],
   "source": [
    "store_relational_JH_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c692315",
   "metadata": {},
   "source": [
    "# Doubling Rate Calculation and Filtration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "31689f46",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Using Linear Regression to Approximate the Doubling Rate\n",
    "\n",
    "def get_doubling_time_via_regression(in_array):\n",
    "    '''\n",
    "        Parameters:\n",
    "        ----------\n",
    "        in_array : pandas.series\n",
    "\n",
    "        Returns:\n",
    "        ----------\n",
    "        Doubling rate: double\n",
    "    '''\n",
    "    y = np.array(in_array)\n",
    "    X = np.arange(-1,2).reshape(-1, 1)\n",
    "\n",
    "    assert len(in_array)==3\n",
    "    reg.fit(X,y)\n",
    "    intercept=reg.intercept_\n",
    "    slope=reg.coef_\n",
    "\n",
    "    return intercept/slope"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "868353e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Using Savgol Filter in Groupby Apply Function\n",
    "\n",
    "def savgol_filter(df_input,column='confirmed',window=5):\n",
    "    ''' \n",
    "        parameters:\n",
    "        ----------\n",
    "        df_input : pandas.series\n",
    "        column : str\n",
    "        window : int\n",
    "            used data points to calculate the filter result\n",
    "\n",
    "        Returns:\n",
    "        ----------\n",
    "        df_result: pd.DataFrame\n",
    "            the index of the df_input has to be preserved in result\n",
    "    '''\n",
    "    degree=1\n",
    "    df_result=df_input\n",
    "\n",
    "    filter_in=df_input[column].fillna(0) # attention with the neutral element here\n",
    "\n",
    "    result=signal.savgol_filter(np.array(filter_in),\n",
    "                           window, # window size used for filtering\n",
    "                           1)\n",
    "    df_result[str(column+'_filtered')]=result\n",
    "    return df_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "811c2c39",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Using Rolling Regression to Approximate the Doubling Time\n",
    "\n",
    "def rolling_reg(df_input,col='confirmed'):\n",
    "    ''' \n",
    "        Parameters:\n",
    "        ----------\n",
    "        df_input: pd.DataFrame\n",
    "        col: str\n",
    "            defines the used column\n",
    "        Returns:\n",
    "        ----------\n",
    "        result: pd.DataFrame\n",
    "    '''\n",
    "    days_back=3\n",
    "    result=df_input[col].rolling(\n",
    "                window=days_back,\n",
    "                min_periods=days_back).apply(get_doubling_time_via_regression,raw=False)\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "90353726",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculating Savgol Filter and Returning the Merged Dataframe\n",
    "\n",
    "def calc_filtered_data(df_input,filter_on='confirmed'):\n",
    "    '''\n",
    "        Parameters:\n",
    "        ----------\n",
    "        df_input: pd.DataFrame\n",
    "        filter_on: str\n",
    "            defines the used column\n",
    "        Returns:\n",
    "        ----------\n",
    "        df_output: pd.DataFrame\n",
    "            the result will be joined as a new column on the input data frame\n",
    "    '''\n",
    "    must_contain=set(['state','country',filter_on])\n",
    "    assert must_contain.issubset(set(df_input.columns)), 'Error in calc_filtered_data: Not All Columns in Data Frame'\n",
    "\n",
    "    df_output=df_input.copy() #Duplicating the coloum to avoid overwriting after filtration\n",
    "\n",
    "    pd_filtered_result=df_output[['state','country',filter_on]].groupby(['state','country']).apply(savgol_filter)#.reset_index()\n",
    "\n",
    "    df_output=pd.merge(df_output,pd_filtered_result[[str(filter_on+'_filtered')]],left_index=True,right_index=True,how='left')\n",
    "    \n",
    "    return df_output.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "59fdf514",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculating Approximated Doubling Rate and Returning the Merged Dataframe\n",
    "\n",
    "def calc_doubling_rate(df_input,filter_on='confirmed'):\n",
    "    ''' \n",
    "        Parameters:\n",
    "        ----------\n",
    "        df_input: pd.DataFrame\n",
    "        filter_on: str\n",
    "            defines the used column\n",
    "        Returns:\n",
    "        ----------\n",
    "        df_output: pd.DataFrame\n",
    "            the result will be joined as a new column on the input data frame\n",
    "    '''\n",
    "    must_contain=set(['state','country',filter_on])\n",
    "    assert must_contain.issubset(set(df_input.columns)), ' Erro in calc_filtered_data not all columns in data frame'\n",
    "\n",
    "\n",
    "    pd_DR_result= df_input.groupby(['state','country']).apply(rolling_reg,filter_on).reset_index()\n",
    "\n",
    "    pd_DR_result=pd_DR_result.rename(columns={filter_on:filter_on+'_DR',\n",
    "                             'level_2':'index'})\n",
    "\n",
    "    #Merging Index of Big Table and the Index of Column After Groupby\n",
    "    df_output=pd.merge(df_input,pd_DR_result[['index',str(filter_on+'_DR')]],left_index=True,right_on=['index'],how='left')\n",
    "    df_output=df_output.drop(columns=['index'])\n",
    "\n",
    "    return df_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d15144ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the test slope is: [2.]\n",
      "             date state  country   confirmed  confirmed_filtered  \\\n",
      "140751 2022-07-19    no  Germany  29994679.0          29982354.6   \n",
      "140752 2022-07-20    no  Germany  30131303.0          30109983.0   \n",
      "140753 2022-07-21    no  Germany  30239122.0          30205473.6   \n",
      "140754 2022-07-22    no  Germany  30331131.0          30292747.2   \n",
      "140755 2022-07-23    no  Germany  30331133.0          30380020.8   \n",
      "\n",
      "        confirmed_DR  confirmed_filtered_DR  \n",
      "140751    197.866127             303.523866  \n",
      "140752    216.071584             253.222339  \n",
      "140753    246.451740             269.804637  \n",
      "140754    302.598755             330.510402  \n",
      "140755    658.626947             347.100924  \n"
     ]
    }
   ],
   "source": [
    "test_data_reg=np.array([2,4,6])\n",
    "result=get_doubling_time_via_regression(test_data_reg)\n",
    "print('the test slope is: '+str(result))\n",
    "\n",
    "pd_JH_data=pd.read_csv('../data/processed/COVID_relational_confirmed.csv',sep=';',parse_dates=[0])\n",
    "pd_JH_data=pd_JH_data.sort_values('date',ascending=True).copy()\n",
    "\n",
    "pd_result_larg=calc_filtered_data(pd_JH_data)\n",
    "pd_result_larg=calc_doubling_rate(pd_result_larg)\n",
    "pd_result_larg=calc_doubling_rate(pd_result_larg,'confirmed_filtered')\n",
    "\n",
    "\n",
    "mask=pd_result_larg['confirmed']>100\n",
    "pd_result_larg['confirmed_filtered_DR']=pd_result_larg['confirmed_filtered_DR'].where(mask, other=np.NaN)\n",
    "pd_result_larg.to_csv('../data/processed/COVID_final_set.csv',sep=';',index=False)\n",
    "print(pd_result_larg[pd_result_larg['country']=='Germany'].tail())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5478dae8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             date state country   confirmed  confirmed_filtered  confirmed_DR  \\\n",
      "247689 2022-07-19    no      US  89830497.0          89867409.4    634.148254   \n",
      "247690 2022-07-20    no      US  90046261.0          90031300.6    538.072800   \n",
      "247691 2022-07-21    no      US  90200438.0          90166889.0    486.703188   \n",
      "247692 2022-07-22    no      US  90367064.0          90310906.9    562.367482   \n",
      "247693 2022-07-23    no      US  90390185.0          90454924.8    951.996385   \n",
      "\n",
      "        confirmed_filtered_DR  \n",
      "247689             730.451021  \n",
      "247690             602.759336  \n",
      "247691             601.188637  \n",
      "247692             644.976160  \n",
      "247693             627.081126  \n"
     ]
    }
   ],
   "source": [
    "print(pd_result_larg[pd_result_larg['country']=='US'].tail())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62c6e935",
   "metadata": {},
   "source": [
    "# Dashboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9bdf5134",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\49152\\ads_covid-19\\notebooks\n"
     ]
    }
   ],
   "source": [
    "print(os.getcwd())\n",
    "df_input_large=pd.read_csv('../data/processed/COVID_final_set.csv',sep=';')\n",
    "\n",
    "\n",
    "fig = go.Figure()\n",
    "\n",
    "app = dash.Dash()\n",
    "app.layout = html.Div([\n",
    "\n",
    "    dcc.Markdown('''\n",
    "    # Applied Data Science on COVID-19 data\n",
    "\n",
    "    ### Project Goal: To teach data science by applying a cross industry standard process.\n",
    "    #### It covers the full walkthrough of: automated data gathering, data transformations,filtering, and machine learning to approximate the doubling time, and (static) deployment of responsive dashboard.\n",
    "\n",
    "    '''),\n",
    "\n",
    "    dcc.Markdown('''\n",
    "    ## Multi-Select Country for Visualization\n",
    "    '''),\n",
    "\n",
    "\n",
    "    dcc.Dropdown(\n",
    "        id='country_drop_down',\n",
    "        options=[ {'label': each,'value':each} for each in df_input_large['country'].unique()],\n",
    "        value=['Japan', 'Spain','Australia'], # which are pre-selected\n",
    "        multi=True\n",
    "    ),\n",
    "\n",
    "    dcc.Markdown('''\n",
    "        ## Select Timeline of confirmed COVID-19 cases or the approximated doubling time\n",
    "        '''),\n",
    "    dcc.Dropdown(\n",
    "    id='doubling_time',\n",
    "    options=[\n",
    "        {'label': 'Timeline Confirmed ', 'value': 'confirmed'},\n",
    "        {'label': 'Timeline Confirmed Filtered', 'value': 'confirmed_filtered'},\n",
    "        {'label': 'Timeline Doubling Rate', 'value': 'confirmed_DR'},\n",
    "        {'label': 'Timeline Doubling Rate Filtered', 'value': 'confirmed_filtered_DR'},\n",
    "    ],\n",
    "    value='confirmed',\n",
    "    multi=False\n",
    "    ),\n",
    "\n",
    "    dcc.Graph(figure=fig, id='main_window_slope')\n",
    "])\n",
    "\n",
    "@app.callback(\n",
    "    Output('main_window_slope', 'figure'),\n",
    "    [Input('country_drop_down', 'value'),\n",
    "    Input('doubling_time', 'value')])\n",
    "def update_figure(country_list,show_doubling):\n",
    "\n",
    "\n",
    "    if 'doubling_rate' in show_doubling:\n",
    "        my_yaxis={'type':\"log\",\n",
    "               'title':'Approximated doubling rate over 3 days (larger numbers are better #stayathome)'\n",
    "              }\n",
    "    else:\n",
    "        my_yaxis={'type':\"log\",\n",
    "                  'title':'Confirmed infected people (source johns hopkins csse, log-scale)'\n",
    "              }\n",
    "\n",
    "\n",
    "    traces = []\n",
    "    for each in country_list:\n",
    "\n",
    "        df_plot=df_input_large[df_input_large['country']==each]\n",
    "\n",
    "        if show_doubling=='doubling_rate_filtered':\n",
    "            df_plot=df_plot[['state','country','confirmed','confirmed_filtered','confirmed_DR','confirmed_filtered_DR','date']].groupby(['country','date']).agg(np.mean).reset_index()\n",
    "        else:\n",
    "            df_plot=df_plot[['state','country','confirmed','confirmed_filtered','confirmed_DR','confirmed_filtered_DR','date']].groupby(['country','date']).agg(np.sum).reset_index()\n",
    "       #print(show_doubling)\n",
    "\n",
    "\n",
    "        traces.append(dict(x=df_plot.date,\n",
    "                                y=df_plot[show_doubling],\n",
    "                                mode='markers+lines',\n",
    "                                opacity=0.9,\n",
    "                                name=each\n",
    "                        )\n",
    "                )\n",
    "    return {\n",
    "            'data': traces,\n",
    "            'layout': dict (\n",
    "                width=1280,\n",
    "                height=720,\n",
    "\n",
    "                xaxis={'title':'Timeline',\n",
    "                        'tickangle':-45,\n",
    "                        'nticks':20,\n",
    "                        'tickfont':dict(size=14,color=\"#7f7f7f\"),\n",
    "                      },\n",
    "\n",
    "                yaxis=my_yaxis\n",
    "        )\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c3b478c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dash is running on http://127.0.0.1:8050/\n",
      "\n",
      " * Serving Flask app \"__main__\" (lazy loading)\n",
      " * Environment: production\n",
      "\u001b[31m   WARNING: This is a development server. Do not use it in a production deployment.\u001b[0m\n",
      "\u001b[2m   Use a production WSGI server instead.\u001b[0m\n",
      " * Debug mode: on\n"
     ]
    }
   ],
   "source": [
    "app.run_server(debug=True, use_reloader=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50a4104f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
